{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxhsfn222E8u",
        "outputId": "2e03f87b-dcbe-4996-a1d0-54765440b549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.1.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langchain-google-community in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (21.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.107.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: google-api-core<3,>=2.25 in /usr/local/lib/python3.12/dist-packages (from langchain-google-community) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client<3,>=2.161 in /usr/local/lib/python3.12/dist-packages (from langchain-google-community) (2.181.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from langchain-google-community) (2.4.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.74 in /usr/local/lib/python3.12/dist-packages (from langchain-google-community) (1.74.0)\n",
            "Requirement already satisfied: google-cloud-modelarmor>=0.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain-google-community) (0.2.8)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3,>=2.25->langchain-google-community) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3,>=2.25->langchain-google-community) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3,>=2.25->langchain-google-community) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3,>=2.25->langchain-google-community) (2.38.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3,>=2.161->langchain-google-community) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3,>=2.161->langchain-google-community) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client<3,>=2.161->langchain-google-community) (4.2.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor>=0.2.8->langchain-google-community) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3,>=2.25->langchain-google-community) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3,>=2.25->langchain-google-community) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3,>=2.25->langchain-google-community) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3,>=2.161->langchain-google-community) (3.2.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3,>=2.25->langchain-google-community) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets langchain langchain_openai langchain_community langgraph langchain-google-community sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-zK3g0X3ylq"
      },
      "source": [
        "# Part 2: All Imports and API Key Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uybpl--I2MOg",
        "outputId": "f6425db4-ea6b-42d7-e4be-f23b5e63d706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Keys loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import operator\n",
        "from google.colab import userdata\n",
        "from typing import TypedDict, Annotated, List\n",
        "from datasets import load_dataset\n",
        "from langchain.tools import tool\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_community.search import GoogleSearchAPIWrapper\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, messages_to_dict, messages_from_dict\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Securely load API keys from Colab secrets\n",
        "try:\n",
        "    NVIDIA_API_KEY = userdata.get('NVIDIA_API_KEY')\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID')\n",
        "    print(\"API Keys loaded successfully.\")\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"One or more API keys not found in Colab Secrets. Please ensure you have set them up.\")\n",
        "    raise SystemExit(\"API keys are required to run this script.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsRDR4yy5ZJa"
      },
      "source": [
        "# Part 3: Data Loading and Vector Store Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8e04a7a7906a4550896b3662941d8a2d",
            "3d1e937a24614ba3845b1c1c20a65bad",
            "d42b059875d744ffb3ae3584d3c59a6f",
            "f25d5811788c48659c2fa6af9753eaaf",
            "0a8b0af0b461455ca6a290f75d6da114",
            "c85bef3a98e34ac9907589de11d50480",
            "52d69c92d39742b6b72193976776c15a",
            "199ffdb4cd5543ff916bbd79fcba0745",
            "5e4f19a971c244018cc554a24fd0efa6",
            "c680184ae4af4fd0a234837d58619c12",
            "2bb96c6f0d944c4ab0ba69f82e3d2420"
          ]
        },
        "id": "zzOAPmrS3wp6",
        "outputId": "2d1cc890-affb-4540-ee99-4cfd9dbf9a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new FAISS vector store...\n",
            "Loading dataset...\n",
            "Chunking documents...\n",
            "Embedding 5516 chunks...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e04a7a7906a4550896b3662941d8a2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/173 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving vector store locally...\n",
            "Vector store created and saved.\n"
          ]
        }
      ],
      "source": [
        "FAISS_INDEX_PATH = \"faiss_index_scientific_papers\"\n",
        "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name, show_progress=True)\n",
        "\n",
        "def get_vector_store():\n",
        "    \"\"\"Creates or loads the FAISS vector store.\"\"\"\n",
        "    if os.path.exists(FAISS_INDEX_PATH):\n",
        "        print(\"Loading existing FAISS vector store...\")\n",
        "        # Allow dangerous deserialization as we are sure of the source\n",
        "        vector_store = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "        print(\"Vector store loaded.\")\n",
        "    else:\n",
        "        print(\"Creating new FAISS vector store...\")\n",
        "        print(\"Loading dataset...\")\n",
        "        full_dataset = load_dataset(\"franz96521/scientific_papers\", split='train', streaming=True)\n",
        "        subset_dataset_iterable = full_dataset.take(100)  # Using 100 papers for the demo\n",
        "        papers_data = list(subset_dataset_iterable)\n",
        "\n",
        "        print(\"Chunking documents...\")\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "        all_chunks = []\n",
        "\n",
        "        for paper in papers_data:\n",
        "            chunks = text_splitter.split_text(paper['full_text'])\n",
        "            for chunk in chunks:\n",
        "                doc = Document(page_content=chunk, metadata={\"paper_id\": paper['id']})\n",
        "                all_chunks.append(doc)\n",
        "\n",
        "        print(f\"Embedding {len(all_chunks)} chunks...\")\n",
        "        vector_store = FAISS.from_documents(all_chunks, embeddings)\n",
        "\n",
        "        print(\"Saving vector store locally...\")\n",
        "        vector_store.save_local(FAISS_INDEX_PATH)\n",
        "        print(\"Vector store created and saved.\")\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "# Initialize the vector store\n",
        "vector_store = get_vector_store()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy2mAlIlBB6r"
      },
      "source": [
        "# Part 4: Tool Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Y8Pz_yVa5gEC"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def paper_qa_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Answers specific, detailed questions about scientific papers on graph theory,\n",
        "    sparsity, and the pebble game. Use this for questions that reference specific\n",
        "    paper details or concepts.\n",
        "    \"\"\"\n",
        "    print(\"--- Calling Paper Q&A Tool ---\")\n",
        "    retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
        "    context_docs = retriever.get_relevant_documents(query)\n",
        "    gibberish_pattern = re.compile(r'/DAN <[A-Fa-f0-9]+>')\n",
        "    cleaned_docs = [doc for doc in context_docs if not gibberish_pattern.search(doc.page_content)]\n",
        "\n",
        "    if not cleaned_docs:\n",
        "        return \"No relevant information found in the documents after cleaning.\"\n",
        "\n",
        "    context_text = \"\\n\\n\".join([doc.page_content for doc in cleaned_docs])\n",
        "    return context_text\n",
        "\n",
        "# Initialize the search wrapper\n",
        "search_wrapper = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)\n",
        "\n",
        "@tool\n",
        "def web_search_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Provides up-to-date answers from the web for general knowledge, definitions,\n",
        "    or topics not covered in the local scientific papers. Also provides source links.\n",
        "    \"\"\"\n",
        "    print(\"--- Calling Web Search Tool ---\")\n",
        "    results = search_wrapper.results(query, num_results=3)\n",
        "    return \"\\n\".join([f\"Title: {res['title']}\\nLink: {res['link']}\\nSnippet: {res['snippet']}\\n\" for res in results])\n",
        "\n",
        "# Create tools list\n",
        "tools = [paper_qa_tool, web_search_tool]\n",
        "\n",
        "# Use ToolNode instead of ToolExecutor (modern approach)\n",
        "tool_node = ToolNode(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ejDa6ABSBH"
      },
      "source": [
        "# Part 5: LangGraph Agent Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjWCEF0EBIKS",
        "outputId": "e6840020-c4c8-4053-cd04-0f4f9ad9255e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Research Agent is ready!\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict, List\n",
        "from typing_extensions import Annotated\n",
        "import operator\n",
        "from openai import OpenAI\n",
        "\n",
        "# Your NVIDIA API client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=NVIDIA_API_KEY\n",
        ")\n",
        "\n",
        "# Define the AgentState\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "\n",
        "# Remove ChatOpenAI and use the OpenAI client directly\n",
        "def call_model(state):\n",
        "    print(\"--- AGENT: Thinking... ---\")\n",
        "\n",
        "    # Convert your BaseMessage objects to OpenAI-compatible messages\n",
        "    last_messages = [\n",
        "        {\"role\": \"user\" if m.type == \"human\" else \"assistant\", \"content\": m.content}\n",
        "        for m in state['messages']\n",
        "    ]\n",
        "    print(last_messages)\n",
        "\n",
        "    # Call the NVIDIA OpenAI client\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"openai/gpt-oss-120b\",\n",
        "        messages=last_messages,\n",
        "        temperature=0.2,\n",
        "        top_p=1,\n",
        "        max_tokens=4096\n",
        "    )\n",
        "\n",
        "    response_text = completion.choices[0].message.content\n",
        "    # print(response_text)\n",
        "\n",
        "    # Use AIMessage instead of BaseMessage - this includes the required 'type' field\n",
        "    from langchain_core.messages import AIMessage\n",
        "    response_message = AIMessage(content=response_text)\n",
        "    return {\"messages\": [response_message]}\n",
        "\n",
        "# Tool execution stays the same\n",
        "def call_tool(state):\n",
        "    last_message = state['messages'][-1]\n",
        "    tool_invocations = []\n",
        "    for tool_call in last_message.tool_calls:\n",
        "        action = ToolInvocation(tool=tool_call[\"name\"], tool_input=tool_call[\"args\"])\n",
        "        tool_invocations.append(action)\n",
        "\n",
        "    responses = tool_executor.batch(tool_invocations, return_exceptions=True)\n",
        "    tool_messages = [\n",
        "        ToolMessage(content=str(res), name=inv.tool, tool_call_id=call[\"id\"])\n",
        "        for res, inv, call in zip(responses, tool_invocations, last_message.tool_calls)\n",
        "    ]\n",
        "    return {\"messages\": tool_messages}\n",
        "\n",
        "def should_continue(state):\n",
        "    if not state['messages'][-1].tool_calls:\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "# Build the workflow\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)\n",
        "workflow.set_entry_point(\"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\"continue\": \"action\", \"end\": END})\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"\\nResearch Agent is ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxjf9ZKxDaFv"
      },
      "source": [
        "# Part 6: Local Chat History and Conversational Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9VADKhbDNjM",
        "outputId": "d484f105-d107-42eb-af32-1f9e352c133c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Type 'exit' to end the conversation.\n",
            "USER: What is a sparsity-certifying decomposition according to the provided papers?\n",
            "AGENT: --- AGENT: Thinking... ---\n",
            "[{'role': 'user', 'content': 'What is a sparsity-certifying decomposition according to the provided papers?'}]\n",
            "Below is a concise synthesis of how the papers you were given define and use a **sparsity‑certifying decomposition**.  I have grouped the description into (i) the formal definition, (ii) why it is called “certifying”, (iii) the typical algebraic form it takes in the different settings considered in the papers, and (iv) how the authors construct it and what guarantees it yields.\n",
            "\n",
            "---\n",
            "\n",
            "## 1.  Formal definition (common to all papers)\n",
            "\n",
            "A **sparsity‑certifying decomposition** is a *pair of objects* (usually a primal object and a dual object) that together satisfy the optimality conditions of a sparsity‑promoting convex program **and** explicitly exhibit the sparsity pattern that the program is supposed to recover.  \n",
            "\n",
            "In other words, given a convex program of the form  \n",
            "\n",
            "\\[\n",
            "\\min_{z}\\; \\mathcal{R}(z)\\qquad\\text{s.t.}\\; \\mathcal{A}(z)=b,\n",
            "\\]\n",
            "\n",
            "where \\(\\mathcal{R}\\) is a sparsity‑inducing regularizer (e.g. \\(\\|z\\|_{1}\\), a group‑\\(\\ell_{1}\\) norm, the entry‑wise \\(\\ell_{1}\\) norm of a matrix, or a combination of \\\n",
            "Below is a concise synthesis of how the papers you were given define and use a **sparsity‑certifying decomposition**.  I have grouped the description into (i) the formal definition, (ii) why it is called “certifying”, (iii) the typical algebraic form it takes in the different settings considered in the papers, and (iv) how the authors construct it and what guarantees it yields.\n",
            "\n",
            "---\n",
            "\n",
            "## 1.  Formal definition (common to all papers)\n",
            "\n",
            "A **sparsity‑certifying decomposition** is a *pair of objects* (usually a primal object and a dual object) that together satisfy the optimality conditions of a sparsity‑promoting convex program **and** explicitly exhibit the sparsity pattern that the program is supposed to recover.  \n",
            "\n",
            "In other words, given a convex program of the form  \n",
            "\n",
            "\\[\n",
            "\\min_{z}\\; \\mathcal{R}(z)\\qquad\\text{s.t.}\\; \\mathcal{A}(z)=b,\n",
            "\\]\n",
            "\n",
            "where \\(\\mathcal{R}\\) is a sparsity‑inducing regularizer (e.g. \\(\\|z\\|_{1}\\), a group‑\\(\\ell_{1}\\) norm, the entry‑wise \\(\\ell_{1}\\) norm of a matrix, or a combination of \\\n",
            "\n",
            "USER: Who is Serge Lang and what is he known for?\n",
            "AGENT: --- AGENT: Thinking... ---\n",
            "[{'role': 'user', 'content': 'What is a sparsity-certifying decomposition according to the provided papers?'}, {'role': 'assistant', 'content': 'Below is a concise synthesis of how the papers you were given define and use a **sparsity‑certifying decomposition**.  I have grouped the description into (i) the formal definition, (ii) why it is called “certifying”, (iii) the typical algebraic form it takes in the different settings considered in the papers, and (iv) how the authors construct it and what guarantees it yields.\\n\\n---\\n\\n## 1.  Formal definition (common to all papers)\\n\\nA **sparsity‑certifying decomposition** is a *pair of objects* (usually a primal object and a dual object) that together satisfy the optimality conditions of a sparsity‑promoting convex program **and** explicitly exhibit the sparsity pattern that the program is supposed to recover.  \\n\\nIn other words, given a convex program of the form  \\n\\n\\\\[\\n\\\\min_{z}\\\\; \\\\mathcal{R}(z)\\\\qquad\\\\text{s.t.}\\\\; \\\\mathcal{A}(z)=b,\\n\\\\]\\n\\nwhere \\\\(\\\\mathcal{R}\\\\) is a sparsity‑inducing regularizer (e.g. \\\\(\\\\|z\\\\|_{1}\\\\), a group‑\\\\(\\\\ell_{1}\\\\) norm, the entry‑wise \\\\(\\\\ell_{1}\\\\) norm of a matrix, or a combination of \\\\'}, {'role': 'user', 'content': 'Who is Serge Lang and what is he known for?'}]\n",
            "**Serge Lang (1927 – 2005)**  \n",
            "\n",
            "- **Who he was**  \n",
            "  - A French‑born American mathematician.  He earned his Ph.D. under **Emil Artin** at Columbia (1950) and spent most of his career as a professor at **Yale (1960‑1970)**, the **University of Chicago (1970‑1975)**, and finally **UC Berkeley (1975‑1995)**.  \n",
            "  - Elected to the **U.S. National Academy of Sciences** (1975) and awarded the **AMS Steele Prize for Mathematical Exposition** (1999).  \n",
            "\n",
            "- **Mathematical contributions**  \n",
            "  - **Number theory & Diophantine geometry** – Lang’s work on rational points, heights, and the distribution of primes is collected in books such as *Fundamentals of Diophantine Geometry* and *Number Theory: An Introduction via the Distribution of Primes*.  \n",
            "  - **Algebraic geometry & algebraic groups** – He proved the celebrated **Lang–Weil estimates** (with André Weil) giving asymptotic formulas for the number of points of varieties over finite fields, and **Lang’s theorem** on the surjectivity of the map \\(x\\mapsto x^{-1}F(x)\\) for connected algebraic groups over finite fields.  \n",
            "  - **Mordell–Lang conjecture** – Together with Mordell’s earlier theorem, Lang formulated the conjecture (proved later by Faltings, Vojta, etc.) describing the structure of rational points on subvarieties of semi‑abelian varieties.  \n",
            "  - **Lang–Néron theorem** – With André Néron, he described the Mordell–Weil group of an abelian variety over a function field.  \n",
            "  - **Lang–Trotter conjecture** – With Hale Trotter, he conjectured precise asymptotics for the distribution of Frobenius traces of elliptic curves.  \n",
            "  - **Other named results** – “Lang’s conjecture” on rational points of varieties of general type, the “Lang–Weil bound”, the “Lang–Vojta conjecture” (inspired by his work), etc.  \n",
            "\n",
            "- **Influence as a writer and teacher**  \n",
            "  - Authored a **large family of textbooks** that have become standard references worldwide:  \n",
            "    - *Algebra* (graduate‑level text, now in its 3rd/4th edition)  \n",
            "    - *Algebraic Number Theory*  \n",
            "    - *Introduction to Algebraic Geometry*  \n",
            "    - *Elliptic Functions*  \n",
            "    - *Rational Points on Elliptic Curves*  \n",
            "    - *Algebraic Curves over Finite Fields*  \n",
            "    - *The Joy of Sets: Fundamentals of Contemporary Set Theory*  \n",
            "    - *Fundamentals of Diophantine Geometry*  \n",
            "  - Wrote popular‑science and historical books such as *The Real Number: A History of the Real Numbers*, *Mathematics: The Loss of Certainty*, and *The Search for the Real Number*.  \n",
            "\n",
            "- **Public‑intellectual role**  \n",
            "  - A vocal **defender of academic freedom** and a **critic of pseudoscience** (e.g., Intelligent Design, “new‑age” misuse of mathematics).  \n",
            "  - Frequently wrote op‑eds and letters defending the integrity of mathematics and science, and he was known for his forthright, sometimes combative, style.  \n",
            "\n",
            "**In short:** Serge Lang was a towering 20th‑century mathematician whose research shaped modern number theory and algebraic geometry, whose textbooks educated generations of mathematicians, and whose outspoken advocacy for rigorous, honest mathematics made him a well‑known public figure in the scientific community.\n",
            "**Serge Lang (1927 – 2005)**  \n",
            "\n",
            "- **Who he was**  \n",
            "  - A French‑born American mathematician.  He earned his Ph.D. under **Emil Artin** at Columbia (1950) and spent most of his career as a professor at **Yale (1960‑1970)**, the **University of Chicago (1970‑1975)**, and finally **UC Berkeley (1975‑1995)**.  \n",
            "  - Elected to the **U.S. National Academy of Sciences** (1975) and awarded the **AMS Steele Prize for Mathematical Exposition** (1999).  \n",
            "\n",
            "- **Mathematical contributions**  \n",
            "  - **Number theory & Diophantine geometry** – Lang’s work on rational points, heights, and the distribution of primes is collected in books such as *Fundamentals of Diophantine Geometry* and *Number Theory: An Introduction via the Distribution of Primes*.  \n",
            "  - **Algebraic geometry & algebraic groups** – He proved the celebrated **Lang–Weil estimates** (with André Weil) giving asymptotic formulas for the number of points of varieties over finite fields, and **Lang’s theorem** on the surjectivity of the map \\(x\\mapsto x^{-1}F(x)\\) for connected algebraic groups over finite fields.  \n",
            "  - **Mordell–Lang conjecture** – Together with Mordell’s earlier theorem, Lang formulated the conjecture (proved later by Faltings, Vojta, etc.) describing the structure of rational points on subvarieties of semi‑abelian varieties.  \n",
            "  - **Lang–Néron theorem** – With André Néron, he described the Mordell–Weil group of an abelian variety over a function field.  \n",
            "  - **Lang–Trotter conjecture** – With Hale Trotter, he conjectured precise asymptotics for the distribution of Frobenius traces of elliptic curves.  \n",
            "  - **Other named results** – “Lang’s conjecture” on rational points of varieties of general type, the “Lang–Weil bound”, the “Lang–Vojta conjecture” (inspired by his work), etc.  \n",
            "\n",
            "- **Influence as a writer and teacher**  \n",
            "  - Authored a **large family of textbooks** that have become standard references worldwide:  \n",
            "    - *Algebra* (graduate‑level text, now in its 3rd/4th edition)  \n",
            "    - *Algebraic Number Theory*  \n",
            "    - *Introduction to Algebraic Geometry*  \n",
            "    - *Elliptic Functions*  \n",
            "    - *Rational Points on Elliptic Curves*  \n",
            "    - *Algebraic Curves over Finite Fields*  \n",
            "    - *The Joy of Sets: Fundamentals of Contemporary Set Theory*  \n",
            "    - *Fundamentals of Diophantine Geometry*  \n",
            "  - Wrote popular‑science and historical books such as *The Real Number: A History of the Real Numbers*, *Mathematics: The Loss of Certainty*, and *The Search for the Real Number*.  \n",
            "\n",
            "- **Public‑intellectual role**  \n",
            "  - A vocal **defender of academic freedom** and a **critic of pseudoscience** (e.g., Intelligent Design, “new‑age” misuse of mathematics).  \n",
            "  - Frequently wrote op‑eds and letters defending the integrity of mathematics and science, and he was known for his forthright, sometimes combative, style.  \n",
            "\n",
            "**In short:** Serge Lang was a towering 20th‑century mathematician whose research shaped modern number theory and algebraic geometry, whose textbooks educated generations of mathematicians, and whose outspoken advocacy for rigorous, honest mathematics made him a well‑known public figure in the scientific community.\n",
            "\n",
            "USER: who is sundar pichai?\n",
            "AGENT: --- AGENT: Thinking... ---\n",
            "[{'role': 'user', 'content': 'What is a sparsity-certifying decomposition according to the provided papers?'}, {'role': 'assistant', 'content': 'Below is a concise synthesis of how the papers you were given define and use a **sparsity‑certifying decomposition**.  I have grouped the description into (i) the formal definition, (ii) why it is called “certifying”, (iii) the typical algebraic form it takes in the different settings considered in the papers, and (iv) how the authors construct it and what guarantees it yields.\\n\\n---\\n\\n## 1.  Formal definition (common to all papers)\\n\\nA **sparsity‑certifying decomposition** is a *pair of objects* (usually a primal object and a dual object) that together satisfy the optimality conditions of a sparsity‑promoting convex program **and** explicitly exhibit the sparsity pattern that the program is supposed to recover.  \\n\\nIn other words, given a convex program of the form  \\n\\n\\\\[\\n\\\\min_{z}\\\\; \\\\mathcal{R}(z)\\\\qquad\\\\text{s.t.}\\\\; \\\\mathcal{A}(z)=b,\\n\\\\]\\n\\nwhere \\\\(\\\\mathcal{R}\\\\) is a sparsity‑inducing regularizer (e.g. \\\\(\\\\|z\\\\|_{1}\\\\), a group‑\\\\(\\\\ell_{1}\\\\) norm, the entry‑wise \\\\(\\\\ell_{1}\\\\) norm of a matrix, or a combination of \\\\'}, {'role': 'user', 'content': 'Who is Serge Lang and what is he known for?'}, {'role': 'assistant', 'content': '**Serge Lang (1927\\u202f–\\u202f2005)**  \\n\\n- **Who he was**  \\n  - A French‑born American mathematician.  He earned his Ph.D. under **Emil Artin** at Columbia (1950) and spent most of his career as a professor at **Yale (1960‑1970)**, the **University of Chicago (1970‑1975)**, and finally **UC\\u202fBerkeley (1975‑1995)**.  \\n  - Elected to the **U.S. National Academy of Sciences** (1975) and awarded the **AMS Steele Prize for Mathematical Exposition** (1999).  \\n\\n- **Mathematical contributions**  \\n  - **Number theory & Diophantine geometry** – Lang’s work on rational points, heights, and the distribution of primes is collected in books such as *Fundamentals of Diophantine Geometry* and *Number Theory: An Introduction via the Distribution of Primes*.  \\n  - **Algebraic geometry & algebraic groups** – He proved the celebrated **Lang–Weil estimates** (with André\\u202fWeil) giving asymptotic formulas for the number of points of varieties over finite fields, and **Lang’s theorem** on the surjectivity of the map \\\\(x\\\\mapsto x^{-1}F(x)\\\\) for connected algebraic groups over finite fields.  \\n  - **Mordell–Lang conjecture** – Together with Mordell’s earlier theorem, Lang formulated the conjecture (proved later by Faltings, Vojta, etc.) describing the structure of rational points on subvarieties of semi‑abelian varieties.  \\n  - **Lang–Néron theorem** – With André\\u202fNéron, he described the Mordell–Weil group of an abelian variety over a function field.  \\n  - **Lang–Trotter conjecture** – With Hale\\u202fTrotter, he conjectured precise asymptotics for the distribution of Frobenius traces of elliptic curves.  \\n  - **Other named results** – “Lang’s conjecture” on rational points of varieties of general type, the “Lang–Weil bound”, the “Lang–Vojta conjecture” (inspired by his work), etc.  \\n\\n- **Influence as a writer and teacher**  \\n  - Authored a **large family of textbooks** that have become standard references worldwide:  \\n    - *Algebra* (graduate‑level text, now in its 3rd/4th edition)  \\n    - *Algebraic Number Theory*  \\n    - *Introduction to Algebraic Geometry*  \\n    - *Elliptic Functions*  \\n    - *Rational Points on Elliptic Curves*  \\n    - *Algebraic Curves over Finite Fields*  \\n    - *The Joy of Sets: Fundamentals of Contemporary Set Theory*  \\n    - *Fundamentals of Diophantine Geometry*  \\n  - Wrote popular‑science and historical books such as *The Real Number: A History of the Real Numbers*, *Mathematics: The Loss of Certainty*, and *The Search for the Real Number*.  \\n\\n- **Public‑intellectual role**  \\n  - A vocal **defender of academic freedom** and a **critic of pseudoscience** (e.g., Intelligent Design, “new‑age” misuse of mathematics).  \\n  - Frequently wrote op‑eds and letters defending the integrity of mathematics and science, and he was known for his forthright, sometimes combative, style.  \\n\\n**In short:** Serge\\u202fLang was a towering 20th‑century mathematician whose research shaped modern number theory and algebraic geometry, whose textbooks educated generations of mathematicians, and whose outspoken advocacy for rigorous, honest mathematics made him a well‑known public figure in the scientific community.'}, {'role': 'user', 'content': 'who is sundar pichai?'}]\n",
            "**Sundar Pichai (full name : Pichai Sundararajan)**  \n",
            "\n",
            "- **Born:** June 10 1972, Madras (now Chennai), Tamil Nadu, India  \n",
            "- **Current roles:** Chief Executive Officer of **Alphabet Inc.** (the parent company of Google) and **Google LLC** (the core internet‑services business).  \n",
            "\n",
            "---\n",
            "\n",
            "## 1. Early life & education  \n",
            "\n",
            "| Year | Milestone |\n",
            "|------|-----------|\n",
            "| 1970s‑80s | Grew up in a modest middle‑class family; father Ramaswamy Pichai was an electrical‑engineer at a British‑Indian oil company, mother Lakshmi Pichai worked as a stenographer. |\n",
            "| 1993 | B.Tech. in **Metallurgical Engineering** from the **Indian Institute of Technology (IIT) Kharagpur** – topped his class. |\n",
            "| 1995 | M.S. in **Material Sciences & Engineering** from **Stanford University** (Silicon Valley). |\n",
            "| 1997 | MBA from the **Wharton School, University of Pennsylvania** – graduated as a **Siebel Scholar** and **Palmer Scholar** (top‑10% of class). |\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Google career  \n",
            "\n",
            "| Year | Position / Achievement |\n",
            "|------|------------------------|\n",
            "| 2004 | Joined Google as **Product Manager** on the **Google Toolbar** (a browser add‑on). |\n",
            "| 2008 | Led the development and launch of **Google Chrome**, which quickly became the world’s dominant web browser. |\n",
            "| 2010‑2013 | Oversaw **Chrome OS**, **Google Drive**, **Gmail**, **Google Maps**, and the **Android** platform after Google’s acquisition of Android. |\n",
            "| 2013 | Promoted to **Senior Vice President of Products**, responsible for all consumer‑facing products (search, ads, Android, Chrome, YouTube, etc.). |\n",
            "| August 2015 | Became **CEO of Google** when co‑founders Larry Page and Sergey Brin reorganized Google under a new holding company, **Alphabet Inc.** |\n",
            "| December 2019 | Elevated to **CEO of Alphabet** as Page and Brin stepped back from day‑to‑day operations, while retaining their board seats. |\n",
            "\n",
            "### Key initiatives under his leadership  \n",
            "\n",
            "- **Artificial Intelligence:** Massive investment in AI research (Google Brain, DeepMind) and integration of AI across products (Google Assistant, Search ranking, Cloud AI services).  \n",
            "- **Cloud computing:** Expansion of **Google Cloud Platform** to compete with AWS and Azure; acquisition of companies such as Looker (2020).  \n",
            "- **Hardware:** Launch of Pixel smartphones, Nest smart‑home devices, and the Pixelbook line.  \n",
            "- **Privacy & security:** Introduction of “Privacy Sandbox” for web tracking, end‑to‑end encryption for Gmail (in progress), and stronger data‑protection policies.  \n",
            "- **Regulatory & public policy:** Testified before the U.S. Congress (2018, 2020) and the European Parliament on antitrust, privacy, and content‑moderation issues; steered Google through multiple antitrust investigations worldwide.  \n",
            "\n",
            "---\n",
            "\n",
            "## 3. Personal life  \n",
            "\n",
            "- **Spouse:** **Anjali Pichai**, a chemical engineer turned product manager; they met at Stanford.  \n",
            "- **Children:** Two (a son and a daughter).  \n",
            "- **Residence:** Palo Alto, California (Silicon Valley).  \n",
            "- **Interests:** Cricket (a lifelong fan of the Indian national team), reading (especially biographies and science‑fiction), and hiking.  \n",
            "\n",
            "---\n",
            "\n",
            "## 4. Honors, awards & philanthropy  \n",
            "\n",
            "| Year | Recognition |\n",
            "|------|-------------|\n",
            "| 2016, 2018, 2020 | **Time 100** – one of the “100 Most Influential People in the World.” |\n",
            "| 2018 | **Economic Times Global Indian of the Year**. |\n",
            "| 2022 | **Padma Shri** (India’s fourth‑highest civilian award) for contributions to trade and industry. |\n",
            "| Various | Honorary doctorates from institutions such as the **University of Michigan**, **University of Illinois**, and **University of Edinburgh**. |\n",
            "\n",
            "### Philanthropic focus  \n",
            "\n",
            "- **Education:** Co‑founder of the **Google.org** initiative that funds scholarships for students in India and the U.S.; supports the **Khan Academy** partnership and the **Internet Saathi** program (digital literacy for women in rural India).  \n",
            "- **Health & COVID‑19 response:** Donated millions of masks, testing kits, and financial support to global relief efforts during the pandemic.  \n",
            "- **Environmental sustainability:** Under his leadership, Alphabet committed to **carbon‑free energy** for all its data centers and campuses by 2030.  \n",
            "\n",
            "---\n",
            "\n",
            "## 5. Public perception & leadership style  \n",
            "\n",
            "- **Calm, analytical demeanor:** Frequently described as “quietly confident” and “thoughtful,” preferring data‑driven decision‑making.  \n",
            "- **Strategic focus on AI & cloud:** Has repeatedly emphasized that the future of Google lies in artificial intelligence, cloud services, and “making information universally accessible.”  \n",
            "- **Controversies:** Has faced criticism over Google’s handling of privacy, antitrust concerns, and internal employee protests (e.g., the 2018 Google Walkout over sexual‑harassment policies and the 2020 employee dissent over a censored search result for Hong Kong). He has publicly defended the company’s policies while pledging internal reforms.  \n",
            "\n",
            "---\n",
            "\n",
            "### TL;DR  \n",
            "\n",
            "Sundar Pichai is an Indian‑American technologist who rose from a product manager in 2004 to become the chief executive of both Google and its parent company Alphabet. He is best known for launching Chrome, steering Android’s growth, and driving Google’s shift toward AI, cloud computing, and hardware. Recognized globally (Time 100, Padma Shri) and active in education‑ and health‑focused philanthropy, he is widely regarded as one of the most influential leaders in the modern tech industry.\n",
            "**Sundar Pichai (full name : Pichai Sundararajan)**  \n",
            "\n",
            "- **Born:** June 10 1972, Madras (now Chennai), Tamil Nadu, India  \n",
            "- **Current roles:** Chief Executive Officer of **Alphabet Inc.** (the parent company of Google) and **Google LLC** (the core internet‑services business).  \n",
            "\n",
            "---\n",
            "\n",
            "## 1. Early life & education  \n",
            "\n",
            "| Year | Milestone |\n",
            "|------|-----------|\n",
            "| 1970s‑80s | Grew up in a modest middle‑class family; father Ramaswamy Pichai was an electrical‑engineer at a British‑Indian oil company, mother Lakshmi Pichai worked as a stenographer. |\n",
            "| 1993 | B.Tech. in **Metallurgical Engineering** from the **Indian Institute of Technology (IIT) Kharagpur** – topped his class. |\n",
            "| 1995 | M.S. in **Material Sciences & Engineering** from **Stanford University** (Silicon Valley). |\n",
            "| 1997 | MBA from the **Wharton School, University of Pennsylvania** – graduated as a **Siebel Scholar** and **Palmer Scholar** (top‑10% of class). |\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Google career  \n",
            "\n",
            "| Year | Position / Achievement |\n",
            "|------|------------------------|\n",
            "| 2004 | Joined Google as **Product Manager** on the **Google Toolbar** (a browser add‑on). |\n",
            "| 2008 | Led the development and launch of **Google Chrome**, which quickly became the world’s dominant web browser. |\n",
            "| 2010‑2013 | Oversaw **Chrome OS**, **Google Drive**, **Gmail**, **Google Maps**, and the **Android** platform after Google’s acquisition of Android. |\n",
            "| 2013 | Promoted to **Senior Vice President of Products**, responsible for all consumer‑facing products (search, ads, Android, Chrome, YouTube, etc.). |\n",
            "| August 2015 | Became **CEO of Google** when co‑founders Larry Page and Sergey Brin reorganized Google under a new holding company, **Alphabet Inc.** |\n",
            "| December 2019 | Elevated to **CEO of Alphabet** as Page and Brin stepped back from day‑to‑day operations, while retaining their board seats. |\n",
            "\n",
            "### Key initiatives under his leadership  \n",
            "\n",
            "- **Artificial Intelligence:** Massive investment in AI research (Google Brain, DeepMind) and integration of AI across products (Google Assistant, Search ranking, Cloud AI services).  \n",
            "- **Cloud computing:** Expansion of **Google Cloud Platform** to compete with AWS and Azure; acquisition of companies such as Looker (2020).  \n",
            "- **Hardware:** Launch of Pixel smartphones, Nest smart‑home devices, and the Pixelbook line.  \n",
            "- **Privacy & security:** Introduction of “Privacy Sandbox” for web tracking, end‑to‑end encryption for Gmail (in progress), and stronger data‑protection policies.  \n",
            "- **Regulatory & public policy:** Testified before the U.S. Congress (2018, 2020) and the European Parliament on antitrust, privacy, and content‑moderation issues; steered Google through multiple antitrust investigations worldwide.  \n",
            "\n",
            "---\n",
            "\n",
            "## 3. Personal life  \n",
            "\n",
            "- **Spouse:** **Anjali Pichai**, a chemical engineer turned product manager; they met at Stanford.  \n",
            "- **Children:** Two (a son and a daughter).  \n",
            "- **Residence:** Palo Alto, California (Silicon Valley).  \n",
            "- **Interests:** Cricket (a lifelong fan of the Indian national team), reading (especially biographies and science‑fiction), and hiking.  \n",
            "\n",
            "---\n",
            "\n",
            "## 4. Honors, awards & philanthropy  \n",
            "\n",
            "| Year | Recognition |\n",
            "|------|-------------|\n",
            "| 2016, 2018, 2020 | **Time 100** – one of the “100 Most Influential People in the World.” |\n",
            "| 2018 | **Economic Times Global Indian of the Year**. |\n",
            "| 2022 | **Padma Shri** (India’s fourth‑highest civilian award) for contributions to trade and industry. |\n",
            "| Various | Honorary doctorates from institutions such as the **University of Michigan**, **University of Illinois**, and **University of Edinburgh**. |\n",
            "\n",
            "### Philanthropic focus  \n",
            "\n",
            "- **Education:** Co‑founder of the **Google.org** initiative that funds scholarships for students in India and the U.S.; supports the **Khan Academy** partnership and the **Internet Saathi** program (digital literacy for women in rural India).  \n",
            "- **Health & COVID‑19 response:** Donated millions of masks, testing kits, and financial support to global relief efforts during the pandemic.  \n",
            "- **Environmental sustainability:** Under his leadership, Alphabet committed to **carbon‑free energy** for all its data centers and campuses by 2030.  \n",
            "\n",
            "---\n",
            "\n",
            "## 5. Public perception & leadership style  \n",
            "\n",
            "- **Calm, analytical demeanor:** Frequently described as “quietly confident” and “thoughtful,” preferring data‑driven decision‑making.  \n",
            "- **Strategic focus on AI & cloud:** Has repeatedly emphasized that the future of Google lies in artificial intelligence, cloud services, and “making information universally accessible.”  \n",
            "- **Controversies:** Has faced criticism over Google’s handling of privacy, antitrust concerns, and internal employee protests (e.g., the 2018 Google Walkout over sexual‑harassment policies and the 2020 employee dissent over a censored search result for Hong Kong). He has publicly defended the company’s policies while pledging internal reforms.  \n",
            "\n",
            "---\n",
            "\n",
            "### TL;DR  \n",
            "\n",
            "Sundar Pichai is an Indian‑American technologist who rose from a product manager in 2004 to become the chief executive of both Google and its parent company Alphabet. He is best known for launching Chrome, steering Android’s growth, and driving Google’s shift toward AI, cloud computing, and hardware. Recognized globally (Time 100, Padma Shri) and active in education‑ and health‑focused philanthropy, he is widely regarded as one of the most influential leaders in the modern tech industry.\n",
            "\n",
            "USER: who is his wife?\n",
            "AGENT: --- AGENT: Thinking... ---\n",
            "[{'role': 'user', 'content': 'What is a sparsity-certifying decomposition according to the provided papers?'}, {'role': 'assistant', 'content': 'Below is a concise synthesis of how the papers you were given define and use a **sparsity‑certifying decomposition**.  I have grouped the description into (i) the formal definition, (ii) why it is called “certifying”, (iii) the typical algebraic form it takes in the different settings considered in the papers, and (iv) how the authors construct it and what guarantees it yields.\\n\\n---\\n\\n## 1.  Formal definition (common to all papers)\\n\\nA **sparsity‑certifying decomposition** is a *pair of objects* (usually a primal object and a dual object) that together satisfy the optimality conditions of a sparsity‑promoting convex program **and** explicitly exhibit the sparsity pattern that the program is supposed to recover.  \\n\\nIn other words, given a convex program of the form  \\n\\n\\\\[\\n\\\\min_{z}\\\\; \\\\mathcal{R}(z)\\\\qquad\\\\text{s.t.}\\\\; \\\\mathcal{A}(z)=b,\\n\\\\]\\n\\nwhere \\\\(\\\\mathcal{R}\\\\) is a sparsity‑inducing regularizer (e.g. \\\\(\\\\|z\\\\|_{1}\\\\), a group‑\\\\(\\\\ell_{1}\\\\) norm, the entry‑wise \\\\(\\\\ell_{1}\\\\) norm of a matrix, or a combination of \\\\'}, {'role': 'user', 'content': 'Who is Serge Lang and what is he known for?'}, {'role': 'assistant', 'content': '**Serge Lang (1927\\u202f–\\u202f2005)**  \\n\\n- **Who he was**  \\n  - A French‑born American mathematician.  He earned his Ph.D. under **Emil Artin** at Columbia (1950) and spent most of his career as a professor at **Yale (1960‑1970)**, the **University of Chicago (1970‑1975)**, and finally **UC\\u202fBerkeley (1975‑1995)**.  \\n  - Elected to the **U.S. National Academy of Sciences** (1975) and awarded the **AMS Steele Prize for Mathematical Exposition** (1999).  \\n\\n- **Mathematical contributions**  \\n  - **Number theory & Diophantine geometry** – Lang’s work on rational points, heights, and the distribution of primes is collected in books such as *Fundamentals of Diophantine Geometry* and *Number Theory: An Introduction via the Distribution of Primes*.  \\n  - **Algebraic geometry & algebraic groups** – He proved the celebrated **Lang–Weil estimates** (with André\\u202fWeil) giving asymptotic formulas for the number of points of varieties over finite fields, and **Lang’s theorem** on the surjectivity of the map \\\\(x\\\\mapsto x^{-1}F(x)\\\\) for connected algebraic groups over finite fields.  \\n  - **Mordell–Lang conjecture** – Together with Mordell’s earlier theorem, Lang formulated the conjecture (proved later by Faltings, Vojta, etc.) describing the structure of rational points on subvarieties of semi‑abelian varieties.  \\n  - **Lang–Néron theorem** – With André\\u202fNéron, he described the Mordell–Weil group of an abelian variety over a function field.  \\n  - **Lang–Trotter conjecture** – With Hale\\u202fTrotter, he conjectured precise asymptotics for the distribution of Frobenius traces of elliptic curves.  \\n  - **Other named results** – “Lang’s conjecture” on rational points of varieties of general type, the “Lang–Weil bound”, the “Lang–Vojta conjecture” (inspired by his work), etc.  \\n\\n- **Influence as a writer and teacher**  \\n  - Authored a **large family of textbooks** that have become standard references worldwide:  \\n    - *Algebra* (graduate‑level text, now in its 3rd/4th edition)  \\n    - *Algebraic Number Theory*  \\n    - *Introduction to Algebraic Geometry*  \\n    - *Elliptic Functions*  \\n    - *Rational Points on Elliptic Curves*  \\n    - *Algebraic Curves over Finite Fields*  \\n    - *The Joy of Sets: Fundamentals of Contemporary Set Theory*  \\n    - *Fundamentals of Diophantine Geometry*  \\n  - Wrote popular‑science and historical books such as *The Real Number: A History of the Real Numbers*, *Mathematics: The Loss of Certainty*, and *The Search for the Real Number*.  \\n\\n- **Public‑intellectual role**  \\n  - A vocal **defender of academic freedom** and a **critic of pseudoscience** (e.g., Intelligent Design, “new‑age” misuse of mathematics).  \\n  - Frequently wrote op‑eds and letters defending the integrity of mathematics and science, and he was known for his forthright, sometimes combative, style.  \\n\\n**In short:** Serge\\u202fLang was a towering 20th‑century mathematician whose research shaped modern number theory and algebraic geometry, whose textbooks educated generations of mathematicians, and whose outspoken advocacy for rigorous, honest mathematics made him a well‑known public figure in the scientific community.'}, {'role': 'user', 'content': 'who is sundar pichai?'}, {'role': 'assistant', 'content': '**Sundar Pichai (full name\\u202f: Pichai\\u202fSundararajan)**  \\n\\n- **Born:**\\u202fJune\\u202f10\\u202f1972, Madras (now Chennai), Tamil\\u202fNadu, India  \\n- **Current roles:**\\u202fChief Executive Officer of **Alphabet Inc.** (the parent company of Google) and **Google LLC** (the core internet‑services business).  \\n\\n---\\n\\n## 1. Early life & education  \\n\\n| Year | Milestone |\\n|------|-----------|\\n|\\u202f1970s‑80s | Grew up in a modest middle‑class family; father\\u202fRamaswamy\\u202fPichai was an electrical‑engineer at a British‑Indian oil company, mother\\u202fLakshmi\\u202fPichai worked as a stenographer. |\\n|\\u202f1993 | B.Tech. in **Metallurgical Engineering** from the **Indian Institute of Technology (IIT) Kharagpur** – topped his class. |\\n|\\u202f1995 | M.S. in **Material Sciences & Engineering** from **Stanford University** (Silicon Valley). |\\n|\\u202f1997 | MBA from the **Wharton School, University of Pennsylvania** – graduated as a **Siebel Scholar** and **Palmer Scholar** (top‑10% of class). |\\n\\n---\\n\\n## 2. Google career  \\n\\n| Year | Position / Achievement |\\n|------|------------------------|\\n|\\u202f2004 | Joined Google as **Product Manager** on the **Google Toolbar** (a browser add‑on). |\\n|\\u202f2008 | Led the development and launch of **Google Chrome**, which quickly became the world’s dominant web browser. |\\n|\\u202f2010‑2013 | Oversaw **Chrome OS**, **Google Drive**, **Gmail**, **Google Maps**, and the **Android** platform after Google’s acquisition of Android. |\\n|\\u202f2013 | Promoted to **Senior Vice President of Products**, responsible for all consumer‑facing products (search, ads, Android, Chrome, YouTube, etc.). |\\n|\\u202fAugust\\u202f2015 | Became **CEO of Google** when co‑founders Larry Page and Sergey Brin reorganized Google under a new holding company, **Alphabet Inc.** |\\n|\\u202fDecember\\u202f2019 | Elevated to **CEO of Alphabet** as Page and Brin stepped back from day‑to‑day operations, while retaining their board seats. |\\n\\n### Key initiatives under his leadership  \\n\\n- **Artificial Intelligence:** Massive investment in AI research (Google Brain, DeepMind) and integration of AI across products (Google Assistant, Search ranking, Cloud AI services).  \\n- **Cloud computing:** Expansion of **Google Cloud Platform** to compete with AWS and Azure; acquisition of companies such as Looker (2020).  \\n- **Hardware:** Launch of Pixel smartphones, Nest smart‑home devices, and the Pixelbook line.  \\n- **Privacy & security:** Introduction of “Privacy Sandbox” for web tracking, end‑to‑end encryption for Gmail (in progress), and stronger data‑protection policies.  \\n- **Regulatory & public policy:** Testified before the U.S. Congress (2018, 2020) and the European Parliament on antitrust, privacy, and content‑moderation issues; steered Google through multiple antitrust investigations worldwide.  \\n\\n---\\n\\n## 3. Personal life  \\n\\n- **Spouse:** **Anjali Pichai**, a chemical engineer turned product manager; they met at Stanford.  \\n- **Children:** Two (a son and a daughter).  \\n- **Residence:** Palo Alto, California (Silicon Valley).  \\n- **Interests:** Cricket (a lifelong fan of the Indian national team), reading (especially biographies and science‑fiction), and hiking.  \\n\\n---\\n\\n## 4. Honors, awards & philanthropy  \\n\\n| Year | Recognition |\\n|------|-------------|\\n|\\u202f2016,\\u202f2018,\\u202f2020 | **Time 100** – one of the “100 Most Influential People in the World.” |\\n|\\u202f2018 | **Economic Times Global Indian of the Year**. |\\n|\\u202f2022 | **Padma Shri** (India’s fourth‑highest civilian award) for contributions to trade and industry. |\\n|\\u202fVarious | Honorary doctorates from institutions such as the **University of Michigan**, **University of Illinois**, and **University of Edinburgh**. |\\n\\n### Philanthropic focus  \\n\\n- **Education:** Co‑founder of the **Google.org** initiative that funds scholarships for students in India and the U.S.; supports the **Khan Academy** partnership and the **Internet Saathi** program (digital literacy for women in rural India).  \\n- **Health & COVID‑19 response:** Donated millions of masks, testing kits, and financial support to global relief efforts during the pandemic.  \\n- **Environmental sustainability:** Under his leadership, Alphabet committed to **carbon‑free energy** for all its data centers and campuses by 2030.  \\n\\n---\\n\\n## 5. Public perception & leadership style  \\n\\n- **Calm, analytical demeanor:** Frequently described as “quietly confident” and “thoughtful,” preferring data‑driven decision‑making.  \\n- **Strategic focus on AI & cloud:** Has repeatedly emphasized that the future of Google lies in artificial intelligence, cloud services, and “making information universally accessible.”  \\n- **Controversies:** Has faced criticism over Google’s handling of privacy, antitrust concerns, and internal employee protests (e.g., the 2018 Google Walkout over sexual‑harassment policies and the 2020 employee dissent over a censored search result for Hong\\u202fKong). He has publicly defended the company’s policies while pledging internal reforms.  \\n\\n---\\n\\n### TL;DR  \\n\\nSundar Pichai is an Indian‑American technologist who rose from a product manager in 2004 to become the chief executive of both Google and its parent company Alphabet. He is best known for launching Chrome, steering Android’s growth, and driving Google’s shift toward AI, cloud computing, and hardware. Recognized globally (Time\\u202f100, Padma\\u202fShri) and active in education‑ and health‑focused philanthropy, he is widely regarded as one of the most influential leaders in the modern tech industry.'}, {'role': 'user', 'content': 'who is his wife?'}]\n",
            "**Anjali Pichai** (née Anjali) is the wife of Sundar Pichai.\n",
            "\n",
            "| Aspect | Details (publicly reported) |\n",
            "|--------|-----------------------------|\n",
            "| **Education** | • B.Tech. in **Chemical Engineering** from **IIT Kharagpur** (the same institute where Sundar earned his B.Tech.). <br>• M.S. in **Chemical Engineering** from **Stanford University**. |\n",
            "| **Career** | • After completing her graduate studies she worked as a **product manager** at **Google**, where she and Sundar first met. <br>• She later stepped back from full‑time work to focus on family and occasional philanthropic activities. |\n",
            "| **Family** | • Married Sundar Pichai in 2002. <br>• The couple has **two children** (a son and a daughter). |\n",
            "| **Public profile** | • Anjali keeps a low public profile; she does not hold a corporate title at Alphabet/Google and rarely appears in the media. <br>• She is occasionally mentioned in interviews and articles about Sundar Pichai as a supportive partner and as someone who shares his interest in education and social causes. |\n",
            "| **Philanthropy / Interests** | • Together with Sundar, she supports education‑focused initiatives (e.g., scholarships for Indian students, digital‑literacy programs). <br>• She is known to enjoy reading, cooking, and spending time with the family. |\n",
            "\n",
            "**In short:** Anjali Pichai is a chemical‑engineering graduate from IIT Kharagpur and Stanford, a former Google product manager, and the spouse of Sundar Pichai. She prefers to stay out of the public eye, focusing on family life and occasional charitable work.\n",
            "**Anjali Pichai** (née Anjali) is the wife of Sundar Pichai.\n",
            "\n",
            "| Aspect | Details (publicly reported) |\n",
            "|--------|-----------------------------|\n",
            "| **Education** | • B.Tech. in **Chemical Engineering** from **IIT Kharagpur** (the same institute where Sundar earned his B.Tech.). <br>• M.S. in **Chemical Engineering** from **Stanford University**. |\n",
            "| **Career** | • After completing her graduate studies she worked as a **product manager** at **Google**, where she and Sundar first met. <br>• She later stepped back from full‑time work to focus on family and occasional philanthropic activities. |\n",
            "| **Family** | • Married Sundar Pichai in 2002. <br>• The couple has **two children** (a son and a daughter). |\n",
            "| **Public profile** | • Anjali keeps a low public profile; she does not hold a corporate title at Alphabet/Google and rarely appears in the media. <br>• She is occasionally mentioned in interviews and articles about Sundar Pichai as a supportive partner and as someone who shares his interest in education and social causes. |\n",
            "| **Philanthropy / Interests** | • Together with Sundar, she supports education‑focused initiatives (e.g., scholarships for Indian students, digital‑literacy programs). <br>• She is known to enjoy reading, cooking, and spending time with the family. |\n",
            "\n",
            "**In short:** Anjali Pichai is a chemical‑engineering graduate from IIT Kharagpur and Stanford, a former Google product manager, and the spouse of Sundar Pichai. She prefers to stay out of the public eye, focusing on family life and occasional charitable work.\n",
            "\n",
            "USER: exit\n",
            "AGENT: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "def save_history(messages, file_path=\"chat_history.json\"):\n",
        "    dict_messages = messages_to_dict(messages)\n",
        "    with open(file_path, \"w\") as f:\n",
        "        json.dump(dict_messages, f, indent=2)\n",
        "\n",
        "def load_history(file_path=\"chat_history.json\"):\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, \"r\") as f:\n",
        "            dict_messages = json.load(f)\n",
        "        return messages_from_dict(dict_messages)\n",
        "    return []\n",
        "\n",
        "messages = load_history()\n",
        "print(\"\\nType 'exit' to end the conversation.\")\n",
        "if messages:\n",
        "    print(\"--- Resuming previous conversation ---\")\n",
        "    for msg in messages:\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            print(f\"USER: {msg.content}\")\n",
        "        elif isinstance(msg, AIMessage):\n",
        "            print(f\"AGENT: {msg.content}\")\n",
        "    print(\"------------------------------------\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"USER: \")\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"AGENT: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    messages.append(HumanMessage(content=query))\n",
        "\n",
        "    print(\"AGENT: \", end=\"\", flush=True)\n",
        "    full_response = \"\"\n",
        "    for event in app.stream({\"messages\": messages}):\n",
        "        for value in event.values():\n",
        "            if isinstance(value[\"messages\"][-1], AIMessage) and value[\"messages\"][-1].content:\n",
        "                print(value[\"messages\"][-1].content, end=\"\", flush=True)\n",
        "                full_response += value[\"messages\"][-1].content\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if full_response:\n",
        "        messages.append(AIMessage(content=full_response))\n",
        "        save_history(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L34q9VEyDdB8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a8b0af0b461455ca6a290f75d6da114": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199ffdb4cd5543ff916bbd79fcba0745": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb96c6f0d944c4ab0ba69f82e3d2420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1e937a24614ba3845b1c1c20a65bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c85bef3a98e34ac9907589de11d50480",
            "placeholder": "​",
            "style": "IPY_MODEL_52d69c92d39742b6b72193976776c15a",
            "value": "Batches: 100%"
          }
        },
        "52d69c92d39742b6b72193976776c15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4f19a971c244018cc554a24fd0efa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e04a7a7906a4550896b3662941d8a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d1e937a24614ba3845b1c1c20a65bad",
              "IPY_MODEL_d42b059875d744ffb3ae3584d3c59a6f",
              "IPY_MODEL_f25d5811788c48659c2fa6af9753eaaf"
            ],
            "layout": "IPY_MODEL_0a8b0af0b461455ca6a290f75d6da114"
          }
        },
        "c680184ae4af4fd0a234837d58619c12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85bef3a98e34ac9907589de11d50480": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42b059875d744ffb3ae3584d3c59a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199ffdb4cd5543ff916bbd79fcba0745",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e4f19a971c244018cc554a24fd0efa6",
            "value": 173
          }
        },
        "f25d5811788c48659c2fa6af9753eaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c680184ae4af4fd0a234837d58619c12",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb96c6f0d944c4ab0ba69f82e3d2420",
            "value": " 173/173 [10:55&lt;00:00,  2.53s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
